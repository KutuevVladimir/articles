\section{Design Principles}

Basic principles of proposed design described in this section.
Here we will use .NET-like style for generic types: $\texttt{Type}_1\langle\texttt{Type}_2\rangle$ means that the type $\texttt{Type}_1$ is generic and $\texttt{Type}_2$ is a type parameter.
Also we use F\#-like type notations and syntax in our examples.

\subsection{Types tor Graphs, Matrices, and Operations}

Suppose one has an edge-labeled graph $G$ where labels have type $\texttt{T}_{\texttt{lbl}}$.
Suppose also one declares a generic type $\texttt{Matrix} \langle \texttt{T} \rangle$ to use this type for graph representation where type parameter \texttt{T} is a type of matrix cell.
It is obvious that type of cell of adjacency matrix of graph $G$ should a special type which has only two values: some value of type $\texttt{T}_{\texttt{lbl}}$ or special value \texttt{Nothing}.
This idea can be naturally expressed using discriminated unions (or sum types) which actively used not only in functional languages such as F\#, OCalm, or Haskell, but also in TypeScript, Swift and other popular languages.
Moreover, the described case is widely used and there is a standard type in almost all languages which supports discriminated unions: $\texttt{Option} \langle \texttt{T} \rangle$ in F\# or OCaml, or $\texttt{Maybe} \langle \texttt{T} \rangle$ in Haskell.
In F\# this type defined as presented in listing~\ref{lst:optionType}.

\begin{listing}[h]
\begin{minted}{fsharp}
type Option<T> = None | Some of T
\end{minted}
\caption{\texttt{Option} type definition}
\label{lst:optionType}
\end{listing}


Thus, to represent the graph $G$ as a matrix one should use an instance of $\texttt{Matrix} \langle \texttt{Option}\langle \texttt{T}_{\texttt{lbl}} \rangle \rangle $  of generic type $\texttt{Matrix}\langle \texttt{T} \rangle$.
This way we can explicitly separate cells which should be stored and which do not: for cells with value \texttt{Some(x)} \texttt{x} should be stored, and for cells with value \texttt{None} should not be stored. Note that there is no storage and data transfer overhead in this solution: one can use any format for sparse matrices and store only $\texttt{T}_{\texttt{lbl}}$ values as usual.

In these settings, natural type for binary operation is $$\texttt{Option}\langle T_1 \rangle \to \texttt{Option}\langle T_2 \rangle \to \texttt{Option}\langle T_3 \rangle.$$ But this type is not restrictive enough: it allows one to define operation which returns some non-zero (\texttt{Some(x)}) value for two zeroes (\texttt{None}-s), while we expect that $$\texttt{None op None = None}$$ for any operation \texttt{op}.  

To solve this problem one can introduce additional type-level constraints, but such constraints can not be expressed in F\#.
Actually, one needs more power type system which supports dependent types.
An alternative solution is to introduce a type $\texttt{AtLeastOne} \langle T_1, T_2 \rangle$ as presented in listing~\ref{lst:AtLeastOneType}. This type is less flexible (for example it disallows one to apply operation partially) but it explicitly shows that we expect that at least one argument of operation should be non-zero.

\begin{listing}[h]
    \begin{minted}{fsharp}
    type AtLeastOne<T1,T2> =
    | Both of T1 * T2
    | Left of T1
    | Right of T2
    \end{minted}
    \caption{\texttt{AtLeastOne} type definition}
    \label{lst:AtLeastOneType}
\end{listing}

Finally in this settings binary operations should have the following type: $$\texttt{AtLeastOne} \langle T_1, T_2 \rangle \to \texttt{Option}\langle T_3 \rangle.$$
This type disallows one to build a non-zero value from two zeroes, and explicitly shows whether the result should be stored or not.
Thus, the proposed typing scheme solves the \textit{problem of explicit and implicit zeroes}.
Moreover it allows one to generalize element-wise operations.
For example, binary operations for element-wise addition, element-wise multiplication, and even for masking can be described as presented in listings~\ref{lst:opIntAdd}, \ref{lst:opIntMult}, \ref{lst:opMask} respectively.

\begin{listing}[h]
    \begin{minted}{fsharp}
let op_int_add args =
    match args with
    | Both (x, y) -> 
        let res = x + y 
        if res = 0 then None else Some res 
    | Left x -> Some x
    | Right y -> Some y
    \end{minted}
    \caption{An example of element-wise addition operation which explicitly filter zeroes out}
    \label{lst:opIntAdd}
\end{listing}

\begin{listing}[h]
    \begin{minted}{fsharp}
let op_int_add args =
    match args with
    | Both (x, y) -> Some (x + y) 
    | Left x -> Some x
    | Right y -> Some y
    \end{minted}
    \caption{An example of element-wise addition operation which preserves zeroes}
    \label{lst:opIntAdd_Zero}
\end{listing}


\begin{listing}[h]
    \begin{minted}{fsharp}
let op_int_mult args =
    match args with
    | Both (x, y) -> 
        let res = x * y 
        if res = 0 then None else Some res 
    | Left x | Right y -> None
    \end{minted}
    \caption{An example of element-wise multiplication operation definition}
    \label{lst:opIntMult}
\end{listing}

\begin{listing}[h]
    \begin{minted}{fsharp}
let op_mask args =
    match args with
    | Both (x, y) -> Some x
    | Left x | Right y -> None
    \end{minted}
    \caption{An example of masking operation definition}
    \label{lst:opMask}
\end{listing}

\subsection{Operations Over Matrices and Vectors}

GraphBLAS API introduces \textbf{monoid} and \textbf{semiring} abstraction to specify element-wise operations for functions over matrices and vectors.
We propose to use binary operations instead as parameters for functions over matrices and vectors.
Using proposed types we always know that identity is always \texttt{None}, so we do not need to specify identity separately as a part of semiring or monoid.
Additionally, applications often do not require operations that actually satisfy semiring or monoid properties, so usage of correctly typed functions should be more clear and less confusing than usage of mathematical objects in non-convenient settings.

For example, function for element-wise matrix-matrix operations\footnote{We name it \texttt{map2} to be consistent with similar functions over standard collections.} should has the following type:
\begin{alignat*}{2}
    \texttt{map2} & : & \\ 
        &   & \texttt{ op: AtLeastOne} \langle T_1, T_2 \rangle \to \texttt{Option} \langle T_3 \rangle \\
        & \to & \texttt{m}_1: \texttt{Matrix} \langle \texttt{Option} \langle T_1\rangle \rangle \\
        & \to & \texttt{m}_2: \texttt{Matrix} \langle \texttt{Option} \langle T_2 \rangle \rangle \\
        & \to & \texttt{result}: \texttt{Matrix} \langle \texttt{Option} \langle T_3\rangle \rangle
\end{alignat*}

In these settings we can predefine a set of widely used binary operations, and allow users to specify their own ones, and combine all of them freely and safely.
Moreover, this way allows one to introduce monoids and semirings as an additional level of abstraction. This way we can simplify core API: one should implement a relatively small set of high-order generic functions that unify functions from existing API. 

\subsection{Fusion}

\textit{Kernels fusion} is a way to reduce memory allocation for intermediate data structures and it is an important part of GraphBLAS-inspired way to high-performance graph analysis~\cite{10.1145/3466795}. Runtime metaprogramming allows us to implement runtime fusion for kernels: having an expression over matrices and vectors we can build an optimized F\# function from predefined building blocs, and after that translate this optimized version to OpenCL C.

While it is unlikely possible to implement general fusion, it should be possible to provide fusion for a fixed set of operations. This way it is important to minimize API which can be done using high-level abstractions as shown before. This allows us to define \textbf{mask} as a partial case of generic element-wise function (respective operation is presented in listing~\ref{lst:opMask}), not an optional parameter of other functions.
This makes API more homogeneous and clear.
 
