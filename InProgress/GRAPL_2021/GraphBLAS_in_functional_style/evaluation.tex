\section{Evaluation}

While our project\footnote{GraphBLAS\# project page: \url{https://github.com/YaccConstructor/GraphBLAS-sharp}.} is in a very early stage we implemented and evaluated only generic matrix-matrix element-wise function \texttt{map2} to demonstrate that the proposed solution may provide not only a way to an expressive compact high-level API, but also a way to its high-performance implementation. This function implemented for matrices in CSR format. We use Brahma.FSharp to support GPGPUs.  

We evaluate \texttt{map2} function parameterized by two operations: \texttt{op\_int\_add} (listing~\ref{lst:opIntAdd}) to get element-wise addition in terms of GraphBLAS API, and \texttt{op\_int\_mult} (listing~\ref{lst:opIntMult}) to get element-wise multiplication.

\subsection{Environment}
We perform our experiments on the PC with Ubuntu 20.04 installed and with the following hardware configuration: Intel Core i7--4790 CPU, 3.60GHz, 32GB DDR4 RAM with GeForce GTX 2070, 8GB GDDR6, 1.41GHz.

For comparison we choose a SuiteSparse:GraphBLAS as a reference CPU implementation of GraphBLAS API, and CUSP\footnote{Cusp is a CUDA-based library for sparse linear algebra and graph computations: \url{https://cusplibrary.github.io/}.} as a most stable GPGPU implementation of generic sparse linear algebra.

\begin{table}[H]
    \centering
    \caption{Matrices for evaluation}
    \label{matrices}  
    \begin{tabular}{ | c || c | c | c | }
    \hline
    Matrix & Size & NNZ & Squared matrix NNZ \\ \hline
    \hline
    wing & 62 032 & 243 088 & 714,200 \\ \hline
    luxembourg\_osm & 114 599 & 119 666 & 393 261 \\ \hline
    amazon0312 & 400 727 & 3 200 440 & 14 390 544 \\ \hline
    amazon-2008 & 735 323 & 5 158 388 & 25 366 745 \\ \hline
    web-Google & 916 428 & 5 105 039 & 29 710 164 \\ \hline
    webbase-1M & 1 000 005 & 3 105 536 & 51 111 996 \\ \hline
    cit-Patents & 3 774 768 & 16 518 948 & 469 \\ \hline
    \end{tabular}
\end{table}


\subsection {Dataset}

For evaluation we select a set of matrices from SuiteSparse matrix collection\footnote{SuiteSparse matrix collection: \url{https://sparse.tamu.edu/}.}
To simplify the evaluation of element-wise operations over matrices with different structures we precomputed the square of each matrix.
Characteristics of selected matrices are presented in table~\ref{matrices}.

\subsection{Evaluation Results}

\begin{table*}[h]
    \centering    
    \caption{Evaluation results for element-wise operations, time in ms}    
    \label{perf-comparison}
    \begin{tabular}{|c||c|c|c|c||c|c|}
    \hline
    \multirow{3}{*}{Matrix} & \multicolumn{4}{c||}{Elemint-wise addition} & \multicolumn{2}{c|}{Elemint-wise multiplication}\\    
    \cline{2-7}        
    & \multicolumn{2}{c|}{GraphBLAS-sharp} & \multirow{2}{*}{SuiteSparse} & \multirow{2}{*}{CUSP} & \multirow{2}{*}{GraphBLAS-sharp} & \multirow{2}{*}{SuiteSparse}        \\
    &No \texttt{AtLeastOne}&\texttt{AtLeastOne}& & & &\\ 
    \hline
    \hline
    wing            & $4,3 \pm 0,8$       & $4,3 \pm 0,6$      & $2,7\pm 0,9$   & $1,5\pm 0,0$   & $3,7 \pm 0,5$      & $3,5\pm 0,4$\\
    \hline
    luxembourg\_osm & $4,9 \pm 0,7$       & $4,1 \pm 0,5$      & $3,0\pm 1,1$   & $1,2\pm 0,1$  & $3,8 \pm 0,6$      & $3,0\pm 0,6$ \\
    \hline
    amazon0312      & $22,3 \pm 1,3$       & $22,1 \pm 1,3$      & $33,4\pm 0,8$  & $11,0\pm 1,4$  & $18,7 \pm 0,9$      & $35,7\pm 1,4$ \\
    \hline
    amazon-2008     & $38,7 \pm 0,8$       & $39,0 \pm 1,0$     & $55,9\pm 1,0$  & $19,1\pm 1,4$ & $34,5 \pm 1,0$     & $58,9\pm 1,9$  \\
    \hline
    web-Google      & $43,4 \pm 0,8$       & $43,4 \pm 1,1$     & $67,2\pm 7,5$  & $21,3\pm 1,3$  & $39,0 \pm 1,2$     & $66,2\pm 0,4$ \\
    \hline
    webbase-1M      & $63,6 \pm 1,1$      & $63,7 \pm 1,3$      & $86,5\pm 2,0$  & $24,3\pm 1,3$  & $54,5 \pm 0,7$      & $37,6\pm 5,6$ \\
    \hline
    cit-Patents     & $26,9 \pm 0,7$      & $26,0 \pm 0,7$      & $183,4\pm 5,4$ & $10,8\pm 0,6$   & $24,3 \pm 0,7$      & $162,2\pm 1,7$ \\     
    \hline
    \end{tabular}    
\end{table*}

To benchmark .NET-based implementation we use \textit{BenchmarkDotNet}\footnote{\textit{BenchmarkDotNet}: \url{https://benchmarkdotnet.org/}. Access date: 12.06.2022.} which allows one to automate benchmarking process for .NET platform.
We run each function XXX times, !!!
Time is measured in milliseconds. The time to prepare data and initially transfer it to GPU is not included.

Results of performance evaluation are presented in table~\ref{perf-comparison}.
We can see, that for element-wise addition our implementation slightly slower than SuiteSparse:GraphBLAS for small matrices (\textbf{wing, luxembourg\_osm}) and up to 7 times faster for big matrices (1.5 times median). At the same time our implementation 2.5 times slower than CUSP-based. For element-wise multiplication comparison with SuiteSparse:GraphBLAS shows almost similar results except matrix \textbf{webbase-1M} for which our implementation slower than SuiteSparse:GraphBLAS.

Comparison between original element-wise addition over primitive types, without \texttt{AtLeasOne} and generalized version which uses \texttt{AtLeastOne} type is also presented in table~\ref{perf-comparison}.
We can see, that more complex data types and element-wise operations do not poor performance of matrix-matrix operations because data transfer dominates arithmetic computations for sparse matrices processing, and the proposed abstraction does not increase the memory footprint.
