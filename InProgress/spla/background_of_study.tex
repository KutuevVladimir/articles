\section{Background of Study}

This section provides a brief overview of existing solutions for graph analysis on GPU, and also describes the concepts of the GraphBLAS standard, highlights some of its shortcomings and limitations on the way to a full-fledged GPU implementation.

\subsection{Related Work}

There is a number of graph processing frameworks for a both CPU and GPU analysis. A great survey of such frameworks is done by Batari et al.~\cite{article:batarfi_survey_graphs} and Shi et al.~\cite{article:shi_survey_graphs}. Problems, addressed by those graph processing frameworks on a GPUs, can be categorized into the following major aspects: data layout, memory access patter, workload mapping and graph programming model. While all of them are important for a high-performance analysis, the latter is what the user directly encounters when solving applied problems. A flexible, expressive, and at the same time efficient for implementation graph programming model is one of the determining factors for the widespread use of the framework.

Existing GPU-based frameworks typically adopt vertex-centric model, where computation is defined as a series of user functions, executed over vertices in some parallel fashion. Thus, this model falls into two variations further: gather-apply-scatter (GAS) and bulk synchronous parallel (BSP). 

\textit{GAS model}. Such frameworks as CuSha~\cite{10.1145/2600212.2600227}, MapGraph~\cite{10.1145/2621934.2621936/MapGraph} adopt GAS model. The computation in GAS model consists of three phases, were each phase performs some vertex processing by user-defined functions, while the framework controls the overall phases execution. This model allows to abstract the need of explicit synchronizations, what simplifies analysis and ensures correctness. However, this approach suffers from an extra GPU overhead.

\textit{BSP model}. Medusa~\cite{6497047/Medusa}, Gunrock~\cite{7967137} use BSP model. In this model the computation is divided into a series of supper steps, where local computation occurs within each step with message passing. This model allows local computations, local memory usage, reduces synchronization and kernel launch overhead, but may suffer from workload imbalance among threads in super step. Gunrock, one of the fastest programmable frameworks for GPU graphs analysis~\cite{article:shi_survey_graphs},  has solved this issue introducing several workload mapping techniques. This improvement allows to achieve great speedup in almost all algorithms. However, Gunrock is only Cuda-oriented framework with relatively low-level API, which requires a significant programming effort to implement a particular algorithm for analysis.

The another programming model is linear-algebra based. This model was pioneered by Bulu√ß et al.~\cite{article:combblas} in CombinationalBLAS. This model allows to define graph algorithms using linear algebra operations over matrices and vectors with some custom user-define element-wise operations. This allows one to express complex computations in few lines of code without significant performance sacrifice. What makes it is promising for implementation. 

The research community formalized linear algebra based model in a form of GraphBLAS standard~\cite{7761646}, which has a number of implementations for CPUs, such as high-performance SuiteSparse library~\cite{10.1145/3322125}, and some adaptations for a GPUs analysis. GraphBLAST~\cite{yang2019graphblast} is a GraphBLAS-inspired template-based Nvidia Cuda only library for high-performance analysis, which is still in development.
GBTL~\cite{7529957} is a GraphBLAS-like framework for Cuda GPUs focused on programming language research, API formalization and correctness rather than high performance. 

\subsection{GraphBLAS concepts}

GraphBLAS standard~\cite{7761646} is a mathematical notation translated into a C API. This standard provides linear algebra building blocks for the implementation of graph algorithms in terms of operations over matrices and vectors. Essential parts of this standard are described below.

\textit{Data containers}. Standard provides general M by N matrix and M vector of values, as well as a scalar value. Containers are parameterised by the type of stored elements. As an example, matrix can be used to represent the adjacency matrix of the graph. Vector can be used to store a set of active vertices for traversal purposes. 

\textit{Algebraic structure}. Algebraic structures are called semiring and monoid, where two or one element-wise operations are provided respectively with some semantic requirements. These structures are adapted for containers, so their mathematical properties differ a bit from those, which are stated in classical algebra.

\textit{Operations.} GraphBLAS provides a number of commonly used linear algebra operations, such as \textit{mxv} and \textit{mxm}, element-wise multiplication, etc. Also, there are some extra operations, such as filtering, selection using predicate, reduction of matrix to vector or of vector to scalar, etc.

\textit{Programming constructs}. GraphBLAS provides extra objects, which are required for practical algorithms implementation, such a mask. Masking allows to use structure of matrix or vector to filter result and reduce amount of computations.

\textit{Algorithms.} Using GraphBLAS constructs it is possible with a little effort and with a few lines of code to write generalized graph analysis algorithms, such as BFS, SSSP, PR, TC, etc.

\subsection{GraphBLAS limitations}

Although GraphBLAS is a mature standard with a number of implementations, it has some limitations and shortcomings, discussed in a talk given by John R. Gilbert~\cite{talk:graphblas_did_wrong}. Some of them are explained in the next paragraphs. 

\textit{Lack of interoperability}. GraphBLAS declares opaque objects with hidden from the user structure. It is not possible to somehow extend or interact with an existing standard implementation. However, practical tasks may required integration of existing formats, storage into a library for practical analysis. 

\textit{Little introspection}. GraphBLAS declares a very limited functionality to inspect structure, state, type, behaviour, performance, correctness, progress of library primitives and operations. It is not feasible to build production-ready data-analysis platform without these features, which are common for all modern DBMS and data analysis frameworks.

\textit{Implicit zeros}. GraphBLAS standard tries to use a mix of math and engineering concepts to address the values storage model. As the result, this model is to complex and not obvious for both mathematicians and programmers. Thus, inaccurate storage manipulations may cause a sufficient memory usage increase in user application even if user precisely follows the standard.

\textit{Masking}. GraphBLAS standard provides an ability to apply a mask to filter out result of computations. However, rules for selecting values from a mask are impliscit and rely on selecting raw zero values, like in a C program. This mechanism is not configurable.

\textit{Templates usage}. There is a number of libraries which implement GraphBLAS in a form of C++ interface. These libraries heavily rely on a template meta programming for a generalization of a processed data. This approach simplifies implementation of the library. Auxiliary code is generated by the compiler. However, template-based approach requires the whole project recompilation for each executable and for any change of a user code.

\textit{GPU support}. GraphBLAS has no fully-featured implementation with GPU support. The primary reason for this is the complexity of the standard. There is a number of attempts to adopt GraphBLAS for a GPU analysis. But, most of them are focused only on Nvidia platform, what limits the portability of the potential solution.